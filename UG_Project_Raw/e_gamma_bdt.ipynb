{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba7b9087-86bb-4872-ab9b-5e1340cbb8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uproot in /opt/conda/lib/python3.11/site-packages (5.5.1)\n",
      "Requirement already satisfied: awkward in /opt/conda/lib/python3.11/site-packages (2.7.3)\n",
      "Requirement already satisfied: cramjam>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from uproot) (2.9.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from uproot) (2024.10.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from uproot) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from uproot) (24.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from uproot) (3.5.0)\n",
      "Requirement already satisfied: awkward-cpp==44 in /opt/conda/lib/python3.11/site-packages (from awkward) (44)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.11/site-packages (from awkward) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=4.13.0->awkward) (3.17.0)\n",
      "File exists: /home/jovyan/CheatedRecoFile_5.root\n",
      "File size: 583465641 bytes\n"
     ]
    }
   ],
   "source": [
    "!pip install uproot awkward \n",
    "from uproot_io import Events, View\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os\n",
    "\n",
    "file_path = \"/home/jovyan/CheatedRecoFile_5.root\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"File exists: {file_path}\")\n",
    "    print(f\"File size: {os.path.getsize(file_path)} bytes\")\n",
    "else:\n",
    "    print(f\"File does not exist: {file_path}\")\n",
    "\n",
    "events_unseen = Events(\"CheatedRecoFile_5.root\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4fdbd2-873c-4aa6-aefd-1def5f28d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Step Functions '''\n",
    "\n",
    "# will merely rewrite the functions to use 3d reconstructions. Will evaluate different functions later.\n",
    "\n",
    "def step_length_3d(events, event_idx):\n",
    "    # find all info for the feature\n",
    "    x = events.reco_hits_3d_x[event_idx]\n",
    "    y = events.reco_hits_3d_y[event_idx]\n",
    "    z = events.reco_hits_3d_z[event_idx]\n",
    "    \n",
    "    x_vtx = events.neutrino_vtx_3d_x[event_idx]\n",
    "    y_vtx = events.neutrino_vtx_3d_y[event_idx]\n",
    "    z_vtx = events.neutrino_vtx_3d_z[event_idx]\n",
    "\n",
    "    if len(x) < 3:\n",
    "        print(f'Warning: Event {event_idx} has only {len(x)} hits.')\n",
    "        return None\n",
    "\n",
    "    if events.is_true_track[event_idx]:\n",
    "        print('Warning: Event is a true track')\n",
    "\n",
    "    # finding step length\n",
    "    x_step = min([abs(t - x_vtx) for t in x])\n",
    "    y_step = min([abs(t - y_vtx) for t in y])\n",
    "    z_step = min([abs(t - z_vtx) for t in z])\n",
    "    step_length = np.sqrt(x_step**2 + y_step**2 + z_step**2)\n",
    "\n",
    "    return step_length\n",
    "\n",
    "def adc_step_prod_3d(events, event_idx):\n",
    "    # find all info for the feature\n",
    "    x = events.reco_hits_3d_x[event_idx]\n",
    "    y = events.reco_hits_3d_y[event_idx]\n",
    "    z = events.reco_hits_3d_z[event_idx]\n",
    "    \n",
    "    x_vtx = events.neutrino_vtx_3d_x[event_idx]\n",
    "    y_vtx = events.neutrino_vtx_3d_y[event_idx]\n",
    "    z_vtx = events.neutrino_vtx_3d_z[event_idx]\n",
    "    \n",
    "    adcs = np.array(events.reco_adcs_w[event_idx])\n",
    "    adc_avg = np.mean(adcs)\n",
    "\n",
    "    if len(x) < 3:\n",
    "        print(f'Warning: Event {event_idx} has only {len(x)} hits.')\n",
    "        return None\n",
    "\n",
    "    if events.is_true_track[event_idx]:\n",
    "        print('Warning: Event is a true track')\n",
    "\n",
    "    # finding step length\n",
    "    x_step = min([abs(t - x_vtx) for t in x])\n",
    "    y_step = min([abs(t - y_vtx) for t in y])\n",
    "    z_step = min([abs(t - z_vtx) for t in z])\n",
    "    step_length = np.sqrt(x_step**2 + y_step**2 + z_step**2)\n",
    "\n",
    "    return step_length * adc_avg\n",
    "\n",
    "def adc_step_div_3d(events, event_idx):\n",
    "    # find all info for the feature\n",
    "    x = events.reco_hits_3d_x[event_idx]\n",
    "    y = events.reco_hits_3d_y[event_idx]\n",
    "    z = events.reco_hits_3d_z[event_idx]\n",
    "    \n",
    "    x_vtx = events.neutrino_vtx_3d_x[event_idx]\n",
    "    y_vtx = events.neutrino_vtx_3d_y[event_idx]\n",
    "    z_vtx = events.neutrino_vtx_3d_z[event_idx]\n",
    "    \n",
    "    adcs = np.array(events.reco_adcs_w[event_idx])\n",
    "    adc_avg = np.mean(adcs)\n",
    "\n",
    "    if len(x) < 3:\n",
    "        print(f'Warning: Event {event_idx} has only {len(x)} hits.')\n",
    "        return None\n",
    "\n",
    "    if events.is_true_track[event_idx]:\n",
    "        print('Warning: Event is a true track')\n",
    "\n",
    "    # finding step length\n",
    "    x_step = min([abs(t - x_vtx) for t in x])\n",
    "    y_step = min([abs(t - y_vtx) for t in y])\n",
    "    z_step = min([abs(t - z_vtx) for t in z])\n",
    "    step_length = np.sqrt(x_step**2 + y_step**2 + z_step**2)\n",
    "\n",
    "    return step_length / adc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d215c52-8baa-4a1a-baec-e46d5b8a4c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' New categorisation function '''\n",
    "\n",
    "def categorise_event(events, event_idx):\n",
    "    pdg = events.mc_pdg[event_idx]\n",
    "    if events.is_true_track[event_idx]:\n",
    "        return 'track'\n",
    "    elif pdg in [11, -11]:\n",
    "        return 'e'  \n",
    "    elif pdg == 22:\n",
    "        return 'gamma'\n",
    "    else: return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb66eaf-7a23-479b-a788-80b2cb23315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature data\n",
    "\n",
    "training_events = Events(\"CheatedRecoFile_0.root\") # Train events with same data as Likelihood to ensure fairness\n",
    "\n",
    "''' Code for identifying candidate lepton in event. '''\n",
    "\n",
    "def identify_candidate(events):\n",
    "    identifiers = events.event_number\n",
    "    data = np.arange(0, len(events.event_number))\n",
    "    slices = []\n",
    "    start_idx = 0\n",
    "\n",
    "    # Split data into slices based on changes in identifiers\n",
    "    for i in range(1, len(identifiers)):\n",
    "        if identifiers[i] != identifiers[i - 1]:\n",
    "            slices.append(data[start_idx:i])\n",
    "            start_idx = i  # Update start index for the next slice\n",
    "\n",
    "    slices.append(data[start_idx:])\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for event_number, event_indices in enumerate(slices):  # Enumerate slices to get the event number\n",
    "\n",
    "        w_hits_event = []\n",
    "        indices = []  # To keep track of the corresponding `i` values\n",
    "        \n",
    "        for i in event_indices:\n",
    "            w_hits_event.append(events.reco_hits_w[i])\n",
    "            indices.append(i)  # Store the corresponding `i` values\n",
    "        \n",
    "        # Find the index of the maximum length in w_hits_event\n",
    "        max_idx = max(range(len(w_hits_event)), key=lambda idx: len(w_hits_event[idx]))\n",
    "        \n",
    "        # Retrieve the corresponding `i` value\n",
    "        candidate_idx = indices[max_idx]\n",
    "\n",
    "        results.append((event_number, candidate_idx))\n",
    "    \n",
    "    return results\n",
    "\n",
    "array_0 = identify_candidate(training_events)\n",
    "array_5 = identify_candidate(events_unseen)\n",
    "cheated_0_candidates = [idx[1] for idx in array_0]\n",
    "cheated_5_candidates = [idx[1] for idx in array_5]\n",
    "\n",
    "shower_candidates_0 = []\n",
    "shower_candidates_5 = []\n",
    "\n",
    "for i in cheated_0_candidates:\n",
    "    if training_events.mc_pdg[i] in [-11, 11, 22]:\n",
    "        shower_candidates_0.append(i)\n",
    "\n",
    "for i in cheated_5_candidates:\n",
    "    if events_unseen.mc_pdg[i] in [-11, 11, 22]:\n",
    "        shower_candidates_5.append(i)\n",
    "\n",
    "def prepare_training_data(events, candidate_array):\n",
    "    \"\"\"Prepares the feature matrix and labels for training.\"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for event_idx in candidate_array:\n",
    "        # Calculate feature scores\n",
    "        step1 = step_length_3d(events, event_idx)\n",
    "        step2 = adc_step_prod_3d(events, event_idx)\n",
    "        step3 = adc_step_div_3d(events, event_idx)\n",
    "\n",
    "        # Ensure valid scores\n",
    "        if None in [step1, step2, step3]:\n",
    "            continue\n",
    "\n",
    "        # Append feature vector\n",
    "        features.append([step1, step2, step3])\n",
    "\n",
    "        # Append label\n",
    "        indicator = categorise_event(events, event_idx)\n",
    "        if indicator == 'e':\n",
    "            labels.append(1)\n",
    "        elif indicator == 'gamma':\n",
    "            labels.append(0)\n",
    "\n",
    "    return np.array(features), np.array(labels) # Return as arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02101f6-f18f-4c54-ae49-42fbcd2a41cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Event 36548 has only 0 hits.\n",
      "Warning: Event 36548 has only 0 hits.\n",
      "Warning: Event 36548 has only 0 hits.\n",
      "Warning: Event 59699 has only 0 hits.\n",
      "Warning: Event 59699 has only 0 hits.\n",
      "Warning: Event 59699 has only 0 hits.\n",
      "Warning: Event 132791 has only 2 hits.\n",
      "Warning: Event 132791 has only 2 hits.\n",
      "Warning: Event 132791 has only 2 hits.\n",
      "Warning: Event 138278 has only 0 hits.\n",
      "Warning: Event 138278 has only 0 hits.\n",
      "Warning: Event 138278 has only 0 hits.\n",
      "Warning: Event 147976 has only 0 hits.\n",
      "Warning: Event 147976 has only 0 hits.\n",
      "Warning: Event 147976 has only 0 hits.\n",
      "Warning: Event 174412 has only 0 hits.\n",
      "Warning: Event 174412 has only 0 hits.\n",
      "Warning: Event 174412 has only 0 hits.\n",
      "Warning: Event 192533 has only 2 hits.\n",
      "Warning: Event 192533 has only 2 hits.\n",
      "Warning: Event 192533 has only 2 hits.\n",
      "Warning: Event 202315 has only 0 hits.\n",
      "Warning: Event 202315 has only 0 hits.\n",
      "Warning: Event 202315 has only 0 hits.\n",
      "Warning: Event 217326 has only 0 hits.\n",
      "Warning: Event 217326 has only 0 hits.\n",
      "Warning: Event 217326 has only 0 hits.\n",
      "Warning: Event 261628 has only 0 hits.\n",
      "Warning: Event 261628 has only 0 hits.\n",
      "Warning: Event 261628 has only 0 hits.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Event 280111 has only 0 hits.\n",
      "Warning: Event 280111 has only 0 hits.\n",
      "Warning: Event 280111 has only 0 hits.\n",
      "Warning: Event 295915 has only 0 hits.\n",
      "Warning: Event 295915 has only 0 hits.\n",
      "Warning: Event 295915 has only 0 hits.\n",
      "Warning: Event 302870 has only 0 hits.\n",
      "Warning: Event 302870 has only 0 hits.\n",
      "Warning: Event 302870 has only 0 hits.\n",
      "Warning: Event 343068 has only 0 hits.\n",
      "Warning: Event 343068 has only 0 hits.\n",
      "Warning: Event 343068 has only 0 hits.\n",
      "Warning: Event 356712 has only 0 hits.\n",
      "Warning: Event 356712 has only 0 hits.\n",
      "Warning: Event 356712 has only 0 hits.\n",
      "Warning: Event 370461 has only 2 hits.\n",
      "Warning: Event 370461 has only 2 hits.\n",
      "Warning: Event 370461 has only 2 hits.\n",
      "Warning: Event 377056 has only 0 hits.\n",
      "Warning: Event 377056 has only 0 hits.\n",
      "Warning: Event 377056 has only 0 hits.\n",
      "Warning: Event 479792 has only 0 hits.\n",
      "Warning: Event 479792 has only 0 hits.\n",
      "Warning: Event 479792 has only 0 hits.\n",
      "Warning: Event 33451 has only 0 hits.\n",
      "Warning: Event 33451 has only 0 hits.\n",
      "Warning: Event 33451 has only 0 hits.\n",
      "Warning: Event 109840 has only 0 hits.\n",
      "Warning: Event 109840 has only 0 hits.\n",
      "Warning: Event 109840 has only 0 hits.\n",
      "Warning: Event 125487 has only 0 hits.\n",
      "Warning: Event 125487 has only 0 hits.\n",
      "Warning: Event 125487 has only 0 hits.\n",
      "Warning: Event 127963 has only 0 hits.\n",
      "Warning: Event 127963 has only 0 hits.\n",
      "Warning: Event 127963 has only 0 hits.\n",
      "Warning: Event 130603 has only 2 hits.\n",
      "Warning: Event 130603 has only 2 hits.\n",
      "Warning: Event 130603 has only 2 hits.\n",
      "Warning: Event 204409 has only 0 hits.\n",
      "Warning: Event 204409 has only 0 hits.\n",
      "Warning: Event 204409 has only 0 hits.\n",
      "Warning: Event 212723 has only 0 hits.\n",
      "Warning: Event 212723 has only 0 hits.\n",
      "Warning: Event 212723 has only 0 hits.\n",
      "Warning: Event 219027 has only 0 hits.\n",
      "Warning: Event 219027 has only 0 hits.\n",
      "Warning: Event 219027 has only 0 hits.\n",
      "Warning: Event 247523 has only 0 hits.\n",
      "Warning: Event 247523 has only 0 hits.\n",
      "Warning: Event 247523 has only 0 hits.\n",
      "Warning: Event 268132 has only 0 hits.\n",
      "Warning: Event 268132 has only 0 hits.\n",
      "Warning: Event 268132 has only 0 hits.\n",
      "Warning: Event 274703 has only 0 hits.\n",
      "Warning: Event 274703 has only 0 hits.\n",
      "Warning: Event 274703 has only 0 hits.\n",
      "Warning: Event 284499 has only 0 hits.\n",
      "Warning: Event 284499 has only 0 hits.\n",
      "Warning: Event 284499 has only 0 hits.\n",
      "Warning: Event 296854 has only 0 hits.\n",
      "Warning: Event 296854 has only 0 hits.\n",
      "Warning: Event 296854 has only 0 hits.\n",
      "Warning: Event 313067 has only 0 hits.\n",
      "Warning: Event 313067 has only 0 hits.\n",
      "Warning: Event 313067 has only 0 hits.\n",
      "Warning: Event 323592 has only 0 hits.\n",
      "Warning: Event 323592 has only 0 hits.\n",
      "Warning: Event 323592 has only 0 hits.\n",
      "Warning: Event 328199 has only 0 hits.\n",
      "Warning: Event 328199 has only 0 hits.\n",
      "Warning: Event 328199 has only 0 hits.\n",
      "Warning: Event 351261 has only 0 hits.\n",
      "Warning: Event 351261 has only 0 hits.\n",
      "Warning: Event 351261 has only 0 hits.\n",
      "Warning: Event is a true track\n",
      "Warning: Event is a true track\n",
      "Warning: Event is a true track\n",
      "Warning: Event 450438 has only 0 hits.\n",
      "Warning: Event 450438 has only 0 hits.\n",
      "Warning: Event 450438 has only 0 hits.\n",
      "Warning: Event 468762 has only 0 hits.\n",
      "Warning: Event 468762 has only 0 hits.\n",
      "Warning: Event 468762 has only 0 hits.\n",
      "Warning: Event 502042 has only 0 hits.\n",
      "Warning: Event 502042 has only 0 hits.\n",
      "Warning: Event 502042 has only 0 hits.\n",
      "Warning: Event 511718 has only 0 hits.\n",
      "Warning: Event 511718 has only 0 hits.\n",
      "Warning: Event 511718 has only 0 hits.\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = prepare_training_data(training_events, shower_candidates_0) # Training data\n",
    "x_test, y_test = prepare_training_data(events_unseen, shower_candidates_5) # Testing data - with same data as Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9110f0b6-3194-4604-b04a-c900ef9f60e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 87.56%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4768, 4769]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Evaluate performance on the test set\u001b[39;00m\n\u001b[1;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m bdt\u001b[38;5;241m.\u001b[39mpredict(x_test) \n\u001b[0;32m---> 11\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m     13\u001b[0m classification_rep \u001b[38;5;241m=\u001b[39m classification_report(y_test, y_pred)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4768, 4769]"
     ]
    }
   ],
   "source": [
    "''' Using AdaBoostClassifier'''\n",
    "bdt = AdaBoostClassifier(n_estimators=100, random_state=0, algorithm='SAMME')\n",
    "bdt.fit(x_train, y_train) # Do a BDT model on Training\n",
    "\n",
    "# Evaluate performance on the training set\n",
    "train_accuracy = bdt.score(x_train, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2%}\")\n",
    "\n",
    "# Evaluate performance on the test set\n",
    "y_pred = bdt.predict(x_test) \n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Plot decision scores for the training set\n",
    "train_scores = bdt.decision_function(x_train)\n",
    "min_f = np.round(np.min(train_scores), 1)\n",
    "max_f = np.round(np.max(train_scores), 1)\n",
    "bins = np.linspace(min_f, max_f, 4 * int((max_f - min_f) / 0.1) + 1)\n",
    "\n",
    "cls_0_scores = train_scores[np.where(y_train == 0)]\n",
    "cls_1_scores = train_scores[np.where(y_train == 1)]\n",
    "\n",
    "weights_0 = np.ones_like(cls_0_scores) / len(cls_0_scores)\n",
    "weights_1 = np.ones_like(cls_1_scores) / len(cls_1_scores)\n",
    "\n",
    "plt.hist(cls_0_scores, color='r', weights=weights_0, bins=bins, histtype='step', label='Class 0')\n",
    "plt.hist(cls_1_scores, color='b', weights=weights_1, bins=bins, histtype='step', label='Class 1')\n",
    "plt.legend()\n",
    "plt.title(\"Decision Scores for Training Set\")\n",
    "plt.show()\n",
    "\n",
    "# Visualise classification on the training set\n",
    "titlesize = 30\n",
    "labelsize = 20\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "\n",
    "# Ground truth\n",
    "ax = axes[0]\n",
    "ax.tick_params(axis='x', labelsize=labelsize)\n",
    "ax.tick_params(axis='y', labelsize=labelsize)\n",
    "cls_0 = np.where(y_train == 0)\n",
    "ax.scatter(x_train[cls_0, 0], x_train[cls_0, 1], c=\"r\", label=\"Class 0\")\n",
    "cls_1 = np.where(y_train == 1)\n",
    "ax.scatter(x_train[cls_1, 0], x_train[cls_1, 1], c=\"b\", label=\"Class 1\")\n",
    "ax.set_xlabel(\"Feature 1\", fontsize=labelsize)\n",
    "ax.set_ylabel(\"Feature 2\", fontsize=labelsize)\n",
    "ax.set_title(\"Training Set Truth\", fontsize=titlesize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "# Predictions\n",
    "ax = axes[1]\n",
    "pred = bdt.predict(x_train)\n",
    "ax.tick_params(axis='x', labelsize=labelsize)\n",
    "ax.tick_params(axis='y', labelsize=labelsize)\n",
    "cls_0 = np.where(pred == 0)\n",
    "ax.scatter(x_train[cls_0, 0], x_train[cls_0, 1], c=\"r\", label=\"Class 0\")\n",
    "cls_1 = np.where(pred == 1)\n",
    "ax.scatter(x_train[cls_1, 0], x_train[cls_1, 1], c=\"b\", label=\"Class 1\")\n",
    "ax.set_xlabel(\"Feature 1\", fontsize=labelsize)\n",
    "ax.set_ylabel(\"Feature 2\", fontsize=labelsize)\n",
    "ax.set_title(\"Training Set Classification\", fontsize=titlesize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualise prediction correctness\n",
    "plt.figure(figsize=(12, 12))\n",
    "correct = np.where(pred == y_train)\n",
    "plt.scatter(x_train[correct, 0], x_train[correct, 1], c=\"k\", label=\"Correct\")\n",
    "incorrect = np.where(pred != y_train)\n",
    "plt.scatter(x_train[incorrect, 0], x_train[incorrect, 1], c=\"r\", label=\"Incorrect\")\n",
    "plt.xlabel(\"Feature 1\", fontsize=labelsize)\n",
    "plt.ylabel(\"Feature 2\", fontsize=labelsize)\n",
    "plt.title(\"Training Set Prediction Correctness\", fontsize=titlesize)\n",
    "plt.legend(fontsize=labelsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1231a1-c55a-4432-9525-f0ad0f785300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
